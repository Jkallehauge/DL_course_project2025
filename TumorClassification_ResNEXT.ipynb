{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882fa7e5-32a3-4389-927d-a1fc6c3965f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up paths for data\n",
    "data_root = \"/home/jovyan/nnunet2-mig-7g-80gb-datavol-1/data/Brain-Tumor-Classification\" \n",
    "\n",
    "tr_base  = data_root+\"/Training\"\n",
    "te_base  = data_root+\"/Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25045aee-19e2-4443-8225-c7eedb990b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up Transforms \n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler # remember subset when you divide into training and validation\n",
    "from torchvision import datasets, transforms, utils, models # add models when you import pretrained models for transfer learning\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 512\n",
    "\n",
    "def zscore(x):  # MRI-friendly\n",
    "    return (x - x.mean()) / (x.std() + 1e-8)\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Lambda(lambda im: im.convert('L')),                 # use 'RGB' if truly 3-ch\n",
    "    transforms.Grayscale(num_output_channels=3), \n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), antialias=True),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.02,0.02), scale=(0.95,1.05)),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3, (0.1, 1.0))], p=0.2),\n",
    "    transforms.ColorJitter(brightness=0.10, contrast=0.10),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(zscore),\n",
    "])\n",
    "\n",
    "eval_tf = transforms.Compose([\n",
    "    transforms.Lambda(lambda im: im.convert('L')),\n",
    "    transforms.Grayscale(num_output_channels=3), \n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(zscore),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6edb6a26-dec7-48ef-b06f-b30f74bc7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def get_device():\n",
    "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def to_device(batch, device):\n",
    "    x, y = batch\n",
    "    return x.to(device, non_blocking=True), y.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2250b4ec-c036-46c3-a513-2fbf1e1bd012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n"
     ]
    }
   ],
   "source": [
    "trainset=datasets.ImageFolder(tr_base, transform=train_tf)\n",
    "valset = datasets.ImageFolder(tr_base, transform=eval_tf)\n",
    "testset=datasets.ImageFolder(te_base, transform=eval_tf)\n",
    "\n",
    "\n",
    "print(testset.classes)\n",
    "print(trainset.classes)\n",
    "print(valset.classes)\n",
    "\n",
    "val_fraction=0.2\n",
    "\n",
    "idxs = list(range(len(valset)))\n",
    "rng = np.random.default_rng(42)\n",
    "rng.shuffle(idxs)\n",
    "\n",
    "n_val = int(len(idxs) * val_fraction)\n",
    "val_idx = idxs[:n_val]\n",
    "train_idx = idxs[n_val:]\n",
    "\n",
    "trainset = Subset(trainset, train_idx)\n",
    "valset   = Subset(valset,   val_idx)\n",
    "\n",
    "class_names = datasets.ImageFolder(tr_base).classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1f03f4-4bca-4fab-ad87-e604d7517907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_from_dataset(ds) -> np.ndarray:\n",
    "    \"\"\"Return class indices for ImageFolder or Subset(ImageFolder).\"\"\"\n",
    "    if isinstance(ds, Subset):\n",
    "        base, idxs = ds.dataset, ds.indices\n",
    "        if hasattr(base, \"targets\"):\n",
    "            return np.asarray(base.targets, dtype=int)[idxs]\n",
    "        return np.asarray([base.samples[i][1] for i in idxs], dtype=int)\n",
    "    # ImageFolder\n",
    "    if hasattr(ds, \"targets\"):\n",
    "        return np.asarray(ds.targets, dtype=int)\n",
    "    return np.asarray([y for _, y in ds.samples], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e360bd-166b-410c-b460-5a787a12c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assume you already created trainset (ImageFolder or Subset(ImageFolder))\n",
    "targets = get_targets_from_dataset(trainset)              # shape [N]\n",
    "num_classes = int(targets.max() + 1)\n",
    "\n",
    "# inverse-frequency class weights (simple & effective)\n",
    "class_counts  = np.bincount(targets, minlength=num_classes).astype(float)\n",
    "class_weights = 1.0 / np.maximum(class_counts, 1.0)      # avoid div/0\n",
    "sample_weights = class_weights[targets]                   # per-sample weight\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=torch.as_tensor(sample_weights, dtype=torch.double),\n",
    "    num_samples=len(sample_weights),   # one epoch ~= dataset size\n",
    "    replacement=True                   # allows oversampling of minority class\n",
    ")\n",
    "\n",
    "BATCH = 32\n",
    "WORKERS = 4\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=False,\n",
    "    sampler=sampler,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,                    # optional: keeps batch size stable\n",
    ")\n",
    "\n",
    "# validation/test loaders stay standard (no sampler)\n",
    "val_loader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea5679d-6e88-4216-ad8b-c3eec150a98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n",
      "100%|██████████| 95.8M/95.8M [00:00<00:00, 326MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
      ")\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def build_model(n_classes, freeze_backbone=False):\n",
    "    \"\"\"\n",
    "    Build a ResNeXt-50 (32x4d) model pretrained on ImageNet, \n",
    "    replace classifier for custom number of classes,\n",
    "    and optionally freeze backbone layers.\n",
    "    \"\"\"\n",
    "    # 1️⃣ Load pretrained ResNeXt-50\n",
    "    model = models.resnext50_32x4d(weights=models.ResNeXt50_32X4D_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # 2️⃣ Replace the final fully connected layer\n",
    "    in_feats = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_feats, n_classes)\n",
    "\n",
    "    # 3️⃣ Optionally freeze feature extractor\n",
    "    if freeze_backbone:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(n_classes=4, freeze_backbone=False)\n",
    "print(model)\n",
    "\n",
    "# Verify output\n",
    "import torch\n",
    "x = torch.randn(2, 3, 512, 512)\n",
    "out = model(x)\n",
    "print(out.shape)  # → [2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05dd577a-db40-4a9f-8dfe-b67597b43788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3) Training utilities\n",
    "# ----------------------------\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=8, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best = None\n",
    "        self.count = 0\n",
    "\n",
    "    def step(self, metric):\n",
    "        if self.best is None or metric > self.best + self.min_delta:\n",
    "            self.best = metric\n",
    "            self.count = 0\n",
    "            return False  # do not stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f69ba58b-ae3d-49c4-87e9-520e396056bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def epoch_run(model, loader, criterion, device, train: bool, use_amp: bool,\n",
    "              optimizer=None, scaler=None):\n",
    "    assert (train and optimizer is not None and scaler is not None) or (not train)\n",
    "\n",
    "    model.train() if train else model.eval()\n",
    "\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    # no graph during evaluation\n",
    "    cm = contextlib.nullcontext() if train else torch.no_grad()\n",
    "\n",
    "    with cm:\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.amp.autocast('cuda', enabled=(use_amp and device.type == 'cuda')):\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "\n",
    "            if train:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            running_loss += loss.detach().float().item() * xb.size(0)\n",
    "            pred = logits.argmax(1)\n",
    "            correct += (pred == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca483300-4165-4768-abeb-0bfdf364358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def get_device():\n",
    "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def to_device(batch, device):\n",
    "    x, y = batch\n",
    "    return x.to(device, non_blocking=True), y.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b654cb-f493-43e4-a90f-c2b43f2b3e59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'set_seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     11\u001b[0m seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2025\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mset_seed\u001b[49m(seed)\n\u001b[1;32m     13\u001b[0m device \u001b[38;5;241m=\u001b[39m get_device()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice:\u001b[39m\u001b[38;5;124m\"\u001b[39m, device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'set_seed' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import amp\n",
    "import json\n",
    "\n",
    "seed=2025\n",
    "set_seed(seed)\n",
    "device = get_device()\n",
    "print(\"Device:\", device)\n",
    "\n",
    "DATA_ROOT = data_root \n",
    "BATCH = 32\n",
    "EPOCHS = 500\n",
    "LR = 3e-4\n",
    "FREEZE_BACKBONE = False  # set True to train only the last layer first\n",
    "\n",
    "counts = torch.tensor([670, 653, 328, 652], dtype=torch.float32)\n",
    "beta = 0.999  # can be tuned in [0.99, 0.9999]\n",
    "\n",
    "effective_num = 1.0 - beta ** counts\n",
    "weights = (1.0 - beta) / effective_num\n",
    "weights = weights / weights.sum() * len(counts)\n",
    "print(weights)\n",
    "\n",
    "#trainset, valset, testset, class_names = build_datasets(DATA_ROOT, img_size=224, val_fraction=0.15)\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "scaler = amp.GradScaler('cuda', enabled=(device.type=='cuda'))\n",
    "\n",
    "train_loader = DataLoader(trainset,batch_size=BATCH,sampler=sampler,num_workers=WORKERS,pin_memory=True)                    # optional: keeps batch size stable)\n",
    "val_loader = DataLoader(valset, batch_size=BATCH*2, shuffle=False,num_workers=WORKERS, pin_memory=True, drop_last=False)\n",
    "test_loader = DataLoader(testset, batch_size=BATCH*2, shuffle=False,num_workers=WORKERS, pin_memory=True, drop_last=False)   \n",
    "\n",
    "print(\"Train uses sampler:\", train_loader.sampler.__class__.__name__)\n",
    "print(\"Val uses sampler:  \", val_loader.sampler.__class__.__name__)\n",
    "print(\"Test uses sampler: \", test_loader.sampler.__class__.__name__)\n",
    "\n",
    "model = build_model(n_classes=len(class_names), freeze_backbone=FREEZE_BACKBONE)\n",
    "#model = build_model(n_classes=len(class_names))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "#model = CNN512x3(num_classes=4, in_ch=3, dropout=0.5).to(device)\n",
    "#criterion = nn.CrossEntropyLoss()  \n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "#criterion = FocalLoss(\n",
    "#    gamma=1.5,    # 1.0 = CE; 1.5–2.0 is often best\n",
    "#    reduction='mean'\n",
    "#)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\":   [],\n",
    "    \"train_acc\":  [],\n",
    "    \"val_acc\":    [],\n",
    "}\n",
    "\n",
    "\n",
    "best_loss, best_acc, best_path, best_path_acc = 1000, 0.0, \"best_ResNext_Loss_brain_tumor.pt\", \"best_ResNext_Acc_brain_tumor.pt\"\n",
    "stopper = EarlyStopper(patience=7, min_delta=1e-4)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss, train_acc = epoch_run(model, train_loader, criterion, device, train=True, use_amp=True, optimizer=optimizer, scaler=scaler)\n",
    "    val_loss,   val_acc   = epoch_run(model, val_loader,   criterion, device, train=False, use_amp=True)\n",
    "    #scheduler.step(val_loss)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} | \"\n",
    "          f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
    "          f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\")\n",
    "\n",
    "    # log\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    #Save model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save({\"model\": model.state_dict(),\n",
    "                    \"classes\": class_names}, best_path)\n",
    "        \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({\"model\": model.state_dict(),\n",
    "                    \"classes\": class_names}, best_path_acc)\n",
    "\n",
    "\n",
    "\n",
    "    if stopper.step(val_acc):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Best val loss: {best_loss:.4f}. Saved to: {best_path}\")\n",
    "\n",
    "with open(\"history_ResNext.json\", \"w\") as f:\n",
    "    json.dump(history, f)\n",
    "# ---- after training: plots ----\n",
    "epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, history[\"train_loss\"], label=\"Train loss\")\n",
    "plt.plot(epochs, history[\"val_loss\"],   label=\"Val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# (optional) accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(epochs, history[\"train_acc\"], label=\"Train acc\")\n",
    "plt.plot(epochs, history[\"val_acc\"],   label=\"Val acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# ----------------------------\n",
    "# Evaluation on test (if available)\n",
    "# ----------------------------\n",
    "if test_loader is not None:\n",
    "    ckpt = torch.load(best_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    model.eval()\n",
    "    all_preds, all_tgts = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = to_device((xb, yb), device)\n",
    "            logits = model(xb)\n",
    "            all_preds.append(logits.argmax(1).cpu())\n",
    "            all_tgts.append(yb.cpu())\n",
    "\n",
    "\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    y_true = torch.cat(all_tgts).numpy()\n",
    "    print(\"\\nTest classification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names= class_names, digits=4))\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "885fe5f0-4be5-42fd-8ec6-e71058bee66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13172/528204293.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(best_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test classification report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor     1.0000    0.9935    0.9967       154\n",
      "meningioma_tumor     0.9941    1.0000    0.9970       168\n",
      "        no_tumor     1.0000    1.0000    1.0000        74\n",
      " pituitary_tumor     1.0000    1.0000    1.0000       184\n",
      "\n",
      "        accuracy                         0.9983       580\n",
      "       macro avg     0.9985    0.9984    0.9984       580\n",
      "    weighted avg     0.9983    0.9983    0.9983       580\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[153   1   0   0]\n",
      " [  0 168   0   0]\n",
      " [  0   0  74   0]\n",
      " [  0   0   0 184]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "val_loader = DataLoader(valset, batch_size=BATCH*2, shuffle=False,num_workers=WORKERS, pin_memory=True, drop_last=False)\n",
    "best_path = \"best_ResNext_Loss_brain_tumor.pt\"\n",
    "\n",
    "device = get_device()\n",
    "print(\"Device:\", device)\n",
    "\n",
    "if val_loader is not None:\n",
    "    ckpt = torch.load(best_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds, all_tgts = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = to_device((xb, yb), device)\n",
    "            logits = model(xb)\n",
    "            all_preds.append(logits.argmax(1).cpu())\n",
    "            all_tgts.append(yb.cpu())\n",
    "\n",
    "\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    y_true = torch.cat(all_tgts).numpy()\n",
    "    print(\"\\nTest classification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names= class_names, digits=4))\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3fb03-0d9b-4c25-9649-0ff863d530cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
